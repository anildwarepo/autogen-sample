{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq = ['how to use gpu in machine learning?',\n",
    "        'is python support in azure functions?', \n",
    "        'does databricks support r?',\n",
    "        'tell me about einstien.',\n",
    "        'what are the limitations of Publishing Drawings to 3D DWF?',\n",
    "        'how to change the Railing Extensions at Floor Levels?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agnext_bot\n",
    "await agnext_bot.register_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime.start() took 0.00 ms.\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by GroupChatManager:UserMessage(content='how to use gpu in machine learning?', source='User')\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by tool_use_agent:UserMessage(content='how to use gpu in machine learning?', source='User')\n",
      "[[{'id': '6276f9e7-a795-4a33-a585-1fe4537bb7ec'}, {'docName': 'azure-machine-learning-azureml-part3.pdf'}, {'pageNumber': '288'}, {'title': 'Distributed GPU Training Guide (SDK v2)'}, {'content': \"Distributed GPU training guide (SDK v2) Article · 08/28/2024 APPLIES TO: Python SDK azure-ai-ml v2 (current) [2] Learn more about using distributed GPU training code in Azure Machine Learning. This article helps you run your existing distributed training code, and offers tips and examples for you to follow for each framework: · PyTorch · TensorFlow · Accelerate GPU training with InfiniBand Prerequisites Review the basic concepts of distributed GPU training, such as data parallelism, distributed data parallelism, and model parallelism. Q Tip If you don't know which type of parallelism to use, more than 90% of the time you should use distributed data parallelism. PyTorch Azure Machine Learning supports running distributed jobs using PyTorch's native distributed training capabilities (torch.distributed). Q Tip For data parallelism, the official PyTorch guidance4 is to use DistributedDataParallel (DDP) over DataParallel for both single-node and multi- node distributed training. PyTorch also recommends using DistributedDataParallel over the multiprocessing_package . Azure Machine Learning documentation and examples therefore focus on DistributedDataParallel training. Process group initialization \"}], [{'id': '9c368393-6bcc-491a-a245-3a600326646c'}, {'docName': 'azure-machine-learning-azureml-part6.pdf'}, {'pageNumber': '196'}, {'title': 'Setting Up GPU Cluster and Environment for Azure Machine Learning'}, {'content': \"compute: azureml : gpu-cluster environment : name: torch200-transformers-gpu image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8- ubuntu22.04: latest ® Important The environment torch200-transformers-gpu we've created requires a CUDA 11.8 compatible hardware device to run Torch 2.0 and Ubuntu 20.04. If your GPU device doesn't support this version of CUDA, you can check the alternative torch113-conda. yaml conda environment (also available on the repository), which runs Torch 1.3 over Ubuntu 18.04 with CUDA 10.1. However, acceleration using the optimum and accelerate libraries won't be supported on this configuration. 4. Each deployment runs on compute clusters. They support both Azure Machine Learning Compute clusters (AmlCompute) or Kubernetes clusters. In this example, our model can benefit from GPU acceleration, which is why we use a GPU cluster. Azure CLI Azure CLI az ml compute create -n gpu-cluster -- type amlcompute -- size STANDARD_NV6 -- min-instances 0 -- max-instances 2 1 Note You are not charged for compute at this point as the cluster remains at 0 nodes until a batch endpoint is invoked and a batch scoring job is submitted. Learn more about manage and optimize cost for AmlCompute. 5. Now, let's create the deployment. Azure CLI To create a new deployment under the created endpoint, create a YAML configuration like the following. You can check the full batch endpoint YAML \"}], [{'id': '1c06beca-9352-441a-a509-ffa7fc38d6b8'}, {'docName': 'azure-machine-learning-azureml-part3.pdf'}, {'pageNumber': '223'}, {'title': 'Setting Up and Running a GPU Cluster in Azure Machine Learning'}, {'content': \"You can also find a completed Jupyter Notebook version of this guide on the GitHub samples page. Before you can run the code in this article to create a GPU cluster, you'll need to request a quota increase for your workspace. Set up the job This section sets up the job for training by loading the required Python packages, connecting to a workspace, creating a compute resource to run a command job, and creating an environment to run the job. Connect to the workspace First, you need to connect to your Azure Machine Learning workspace. The Azure Machine Learning workspace is the top-level resource for the service. It provides you with a centralized place to work with all the artifacts you create when you use Azure Machine Learning. We're using DefaultAzureCredential to get access to the workspace. This credential should be capable of handling most Azure SDK authentication scenarios. If DefaultAzureCredential doesn't work for you, see azure-identity reference documentation or Set up authentication for more available credentials. Python # Handle to the workspace from azure. ai.ml import MLClient # Authentication package from azure. identity import DefaultAzureCredential credential = DefaultAzureCredential() If you prefer to use a browser to sign in and authenticate, you should uncomment the following code and use it instead. Python # Handle to the workspace # from azure.ai.ml import MLClient # Authentication package \"}]]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by QA Agent:[UserMessage(content='how to use gpu in machine learning?', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"aml_index_with_suggester\",\"search_query\":\"how to use gpu in machine learning\"} and tool result is: <Context>[[{\"id\": \"6276f9e7-a795-4a33-a585-1fe4537bb7ec\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"288\"}, {\"title\": \"Distributed GPU Training Guide (SDK v2)\"}, {\"content\": \"Distributed GPU training guide (SDK v2) Article \\\\u00b7 08/28/2024 APPLIES TO: Python SDK azure-ai-ml v2 (current) [2] Learn more about using distributed GPU training code in Azure Machine Learning. This article helps you run your existing distributed training code, and offers tips and examples for you to follow for each framework: \\\\u00b7 PyTorch \\\\u00b7 TensorFlow \\\\u00b7 Accelerate GPU training with InfiniBand Prerequisites Review the basic concepts of distributed GPU training, such as data parallelism, distributed data parallelism, and model parallelism. Q Tip If you don\\'t know which type of parallelism to use, more than 90% of the time you should use distributed data parallelism. PyTorch Azure Machine Learning supports running distributed jobs using PyTorch\\'s native distributed training capabilities (torch.distributed). Q Tip For data parallelism, the official PyTorch guidance4 is to use DistributedDataParallel (DDP) over DataParallel for both single-node and multi- node distributed training. PyTorch also recommends using DistributedDataParallel over the multiprocessing_package . Azure Machine Learning documentation and examples therefore focus on DistributedDataParallel training. Process group initialization \"}], [{\"id\": \"9c368393-6bcc-491a-a245-3a600326646c\"}, {\"docName\": \"azure-machine-learning-azureml-part6.pdf\"}, {\"pageNumber\": \"196\"}, {\"title\": \"Setting Up GPU Cluster and Environment for Azure Machine Learning\"}, {\"content\": \"compute: azureml : gpu-cluster environment : name: torch200-transformers-gpu image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8- ubuntu22.04: latest \\\\u00ae Important The environment torch200-transformers-gpu we\\'ve created requires a CUDA 11.8 compatible hardware device to run Torch 2.0 and Ubuntu 20.04. If your GPU device doesn\\'t support this version of CUDA, you can check the alternative torch113-conda. yaml conda environment (also available on the repository), which runs Torch 1.3 over Ubuntu 18.04 with CUDA 10.1. However, acceleration using the optimum and accelerate libraries won\\'t be supported on this configuration. 4. Each deployment runs on compute clusters. They support both Azure Machine Learning Compute clusters (AmlCompute) or Kubernetes clusters. In this example, our model can benefit from GPU acceleration, which is why we use a GPU cluster. Azure CLI Azure CLI az ml compute create -n gpu-cluster -- type amlcompute -- size STANDARD_NV6 -- min-instances 0 -- max-instances 2 1 Note You are not charged for compute at this point as the cluster remains at 0 nodes until a batch endpoint is invoked and a batch scoring job is submitted. Learn more about manage and optimize cost for AmlCompute. 5. Now, let\\'s create the deployment. Azure CLI To create a new deployment under the created endpoint, create a YAML configuration like the following. You can check the full batch endpoint YAML \"}], [{\"id\": \"1c06beca-9352-441a-a509-ffa7fc38d6b8\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"223\"}, {\"title\": \"Setting Up and Running a GPU Cluster in Azure Machine Learning\"}, {\"content\": \"You can also find a completed Jupyter Notebook version of this guide on the GitHub samples page. Before you can run the code in this article to create a GPU cluster, you\\'ll need to request a quota increase for your workspace. Set up the job This section sets up the job for training by loading the required Python packages, connecting to a workspace, creating a compute resource to run a command job, and creating an environment to run the job. Connect to the workspace First, you need to connect to your Azure Machine Learning workspace. The Azure Machine Learning workspace is the top-level resource for the service. It provides you with a centralized place to work with all the artifacts you create when you use Azure Machine Learning. We\\'re using DefaultAzureCredential to get access to the workspace. This credential should be capable of handling most Azure SDK authentication scenarios. If DefaultAzureCredential doesn\\'t work for you, see azure-identity reference documentation or Set up authentication for more available credentials. Python # Handle to the workspace from azure. ai.ml import MLClient # Authentication package from azure. identity import DefaultAzureCredential credential = DefaultAzureCredential() If you prefer to use a browser to sign in and authenticate, you should uncomment the following code and use it instead. Python # Handle to the workspace # from azure.ai.ml import MLClient # Authentication package \"}]] </Context>\\n</Context>', source='tool_use_agent')]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by Evalutor Agent:[UserMessage(content='how to use gpu in machine learning?', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"aml_index_with_suggester\",\"search_query\":\"how to use gpu in machine learning\"} and tool result is: <Context>[[{\"id\": \"6276f9e7-a795-4a33-a585-1fe4537bb7ec\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"288\"}, {\"title\": \"Distributed GPU Training Guide (SDK v2)\"}, {\"content\": \"Distributed GPU training guide (SDK v2) Article \\\\u00b7 08/28/2024 APPLIES TO: Python SDK azure-ai-ml v2 (current) [2] Learn more about using distributed GPU training code in Azure Machine Learning. This article helps you run your existing distributed training code, and offers tips and examples for you to follow for each framework: \\\\u00b7 PyTorch \\\\u00b7 TensorFlow \\\\u00b7 Accelerate GPU training with InfiniBand Prerequisites Review the basic concepts of distributed GPU training, such as data parallelism, distributed data parallelism, and model parallelism. Q Tip If you don\\'t know which type of parallelism to use, more than 90% of the time you should use distributed data parallelism. PyTorch Azure Machine Learning supports running distributed jobs using PyTorch\\'s native distributed training capabilities (torch.distributed). Q Tip For data parallelism, the official PyTorch guidance4 is to use DistributedDataParallel (DDP) over DataParallel for both single-node and multi- node distributed training. PyTorch also recommends using DistributedDataParallel over the multiprocessing_package . Azure Machine Learning documentation and examples therefore focus on DistributedDataParallel training. Process group initialization \"}], [{\"id\": \"9c368393-6bcc-491a-a245-3a600326646c\"}, {\"docName\": \"azure-machine-learning-azureml-part6.pdf\"}, {\"pageNumber\": \"196\"}, {\"title\": \"Setting Up GPU Cluster and Environment for Azure Machine Learning\"}, {\"content\": \"compute: azureml : gpu-cluster environment : name: torch200-transformers-gpu image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8- ubuntu22.04: latest \\\\u00ae Important The environment torch200-transformers-gpu we\\'ve created requires a CUDA 11.8 compatible hardware device to run Torch 2.0 and Ubuntu 20.04. If your GPU device doesn\\'t support this version of CUDA, you can check the alternative torch113-conda. yaml conda environment (also available on the repository), which runs Torch 1.3 over Ubuntu 18.04 with CUDA 10.1. However, acceleration using the optimum and accelerate libraries won\\'t be supported on this configuration. 4. Each deployment runs on compute clusters. They support both Azure Machine Learning Compute clusters (AmlCompute) or Kubernetes clusters. In this example, our model can benefit from GPU acceleration, which is why we use a GPU cluster. Azure CLI Azure CLI az ml compute create -n gpu-cluster -- type amlcompute -- size STANDARD_NV6 -- min-instances 0 -- max-instances 2 1 Note You are not charged for compute at this point as the cluster remains at 0 nodes until a batch endpoint is invoked and a batch scoring job is submitted. Learn more about manage and optimize cost for AmlCompute. 5. Now, let\\'s create the deployment. Azure CLI To create a new deployment under the created endpoint, create a YAML configuration like the following. You can check the full batch endpoint YAML \"}], [{\"id\": \"1c06beca-9352-441a-a509-ffa7fc38d6b8\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"223\"}, {\"title\": \"Setting Up and Running a GPU Cluster in Azure Machine Learning\"}, {\"content\": \"You can also find a completed Jupyter Notebook version of this guide on the GitHub samples page. Before you can run the code in this article to create a GPU cluster, you\\'ll need to request a quota increase for your workspace. Set up the job This section sets up the job for training by loading the required Python packages, connecting to a workspace, creating a compute resource to run a command job, and creating an environment to run the job. Connect to the workspace First, you need to connect to your Azure Machine Learning workspace. The Azure Machine Learning workspace is the top-level resource for the service. It provides you with a centralized place to work with all the artifacts you create when you use Azure Machine Learning. We\\'re using DefaultAzureCredential to get access to the workspace. This credential should be capable of handling most Azure SDK authentication scenarios. If DefaultAzureCredential doesn\\'t work for you, see azure-identity reference documentation or Set up authentication for more available credentials. Python # Handle to the workspace from azure. ai.ml import MLClient # Authentication package from azure. identity import DefaultAzureCredential credential = DefaultAzureCredential() If you prefer to use a browser to sign in and authenticate, you should uncomment the following code and use it instead. Python # Handle to the workspace # from azure.ai.ml import MLClient # Authentication package \"}]] </Context>\\n</Context>', source='tool_use_agent'), AssistantMessage(content=\"Response:To use GPUs in machine learning, you can follow these steps as outlined in the Azure Machine Learning documentation:\\n\\n1. **Set Up the GPU Cluster and Environment**:\\n   - First, create a compute cluster with GPU support. For example, you can use the Azure CLI to create a GPU cluster:\\n     ```bash\\n     az ml compute create -n gpu-cluster --type amlcompute --size STANDARD_NV6 --min-instances 0 --max-instances 2\\n     ```\\n     This creates a GPU cluster that can scale between 0 and 2 instances based on demand [Source: azure-machine-learning-azureml-part6.pdf, Page No.: 196].\\n\\n   - Next, set up an environment compatible with your GPU hardware and necessary libraries:\\n     ```yaml\\n     compute: azureml : gpu-cluster\\n     environment: \\n       name: torch200-transformers-gpu\\n       image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04: latest\\n     ```\\n     Ensure the environment and CUDA versions are compatible with your hardware [Source: azure-machine-learning-azureml-part6.pdf, Page No.: 196].\\n\\n2. **Distributed GPU Training**:\\n   - To run distributed GPU jobs using frameworks like PyTorch, use the native distributed training capabilities. PyTorch's official guidance recommends using `DistributedDataParallel (DDP)` for both single-node and multi-node distributed training:\\n     ```python\\n     from torch.distributed import init_process_group\\n     init_process_group(backend='nccl')\\n     # Use DistributedDataParallel for training\\n     ```\\n     [Source: azure-machine-learning-azureml-part3.pdf, Page No.: 288].\\n\\n3. **Connecting to the Workspace**:\\n   - Connect to the Azure Machine Learning workspace to manage resources and jobs. Use the following Python code to authenticate and connect:\\n     ```python\\n     from azure.ai.ml import MLClient\\n     from azure.identity import DefaultAzureCredential\\n     \\n     credential = DefaultAzureCredential()\\n     ml_client = MLClient(credential, subscription_id, resource_group_name, workspace_name)\\n     ```\\n     If you prefer to use a browser-based authentication, you can uncomment and modify the relevant code in the provided example [Source: azure-machine-learning-azureml-part3.pdf, Page No.: 223].\\n\\nBy following these steps, you can efficiently set up and use GPUs for your machine learning tasks in Azure Machine Learning environments.\", source='qa_agent')]\n",
      "conversation_id delete: 12c3ca71-0c48-41c2-b344-426eb9910390\n",
      "\u001b[35m--------------------\u001b[0m\n",
      "# How to Use GPU in Machine Learning\n",
      "\n",
      "To utilize GPUs in machine learning, especially within the Azure Machine Learning framework, you can follow these steps:\n",
      "\n",
      "## 1. Set Up the GPU Cluster and Environment\n",
      "\n",
      "### Create a GPU Cluster\n",
      "You can use Azure CLI to create a GPU cluster:\n",
      "\n",
      "```bash\n",
      "az ml compute create -n gpu-cluster --type amlcompute --size STANDARD_NV6 --min-instances 0 --max-instances 2\n",
      "```\n",
      "\n",
      "This command sets up a GPU cluster that can scale between 0 and 2 instances based on demand.\n",
      "\n",
      "### Configure Environment and Compatibility\n",
      "Ensure the environment and CUDA versions are compatible with your GPU hardware:\n",
      "\n",
      "```yaml\n",
      "compute: azureml : gpu-cluster\n",
      "environment: \n",
      "  name: torch200-transformers-gpu\n",
      "  image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04:latest\n",
      "```\n",
      "\n",
      "If your GPU doesn't support CUDA 11.8, you can use an alternative environment configuration:\n",
      "\n",
      "```yaml\n",
      "environment: \n",
      "  name: torch113-conda\n",
      "  image: ubuntu18.04\n",
      "```\n",
      "\n",
      "This alternative runs Torch 1.3 over Ubuntu 18.04 with CUDA 10.1 but may not support acceleration libraries.\n",
      "\n",
      "## 2. Distributed GPU Training\n",
      "\n",
      "### Using PyTorch's Native Distributed Training\n",
      "For frameworks like PyTorch, utilize native distributed training capabilities. PyTorch recommends using `DistributedDataParallel (DDP)`:\n",
      "\n",
      "```python\n",
      "from torch.distributed import init_process_group\n",
      "init_process_group(backend='nccl')  # Use NCCL backend\n",
      "# Use DistributedDataParallel for training\n",
      "```\n",
      "\n",
      "## 3. Connect to the Azure Machine Learning Workspace\n",
      "\n",
      "### Authenticate and Connect\n",
      "To manage resources and run jobs, connect to the Azure Machine Learning workspace:\n",
      "\n",
      "```python\n",
      "from azure.ai.ml import MLClient\n",
      "from azure.identity import DefaultAzureCredential\n",
      "\n",
      "credential = DefaultAzureCredential()\n",
      "ml_client = MLClient(credential, subscription_id, resource_group_name, workspace_name)\n",
      "```\n",
      "\n",
      "If you prefer browser-based authentication, modify the code accordingly to support it.\n",
      "\n",
      "## Summary\n",
      "By following these steps, you can efficiently use GPUs for your machine learning tasks within the Azure Machine Learning setup. This includes setting up GPU clusters, configuring environments, running distributed training, and connecting to the workspace to manage resources.\n"
     ]
    }
   ],
   "source": [
    "response = await agnext_bot.start_multiagent_chat(\"how to use gpu in machine learning?\", \"\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime.start() took 0.00 ms.\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by GroupChatManager:UserMessage(content='does databricks support r?', source='User')\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by tool_use_agent:UserMessage(content='does databricks support r?', source='User')\n",
      "[[{'id': '12'}, {'title': 'Azure Databricks'}, {'content': 'Azure Databricks is an Apache Spark-based analytics platform optimized for the Azure cloud. It provides a collaborative workspace for data scientists, engineers, and business users to process, analyze, and visualize big data. Databricks supports multiple programming languages, including Python, Scala, R, and SQL. It offers built-in integration with Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can also use Databricks to train and deploy machine learning models, and integrate with Azure Machine Learning.'}, {'category': 'Analytics'}], [{'id': '83'}, {'title': 'Azure Databricks'}, {'content': 'Azure Databricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Databricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Databricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.'}, {'category': 'Analytics'}], [{'id': '107'}, {'title': 'Azure Data Bricks'}, {'content': 'Azure Data Bricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Data Bricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Data Bricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.'}, {'category': 'Analytics'}]]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by QA Agent:[UserMessage(content='does databricks support r?', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"vectest\",\"search_query\":\"does databricks support r?\",\"top_k\":3} and tool result is: <Context>[[{\"id\": \"12\"}, {\"title\": \"Azure Databricks\"}, {\"content\": \"Azure Databricks is an Apache Spark-based analytics platform optimized for the Azure cloud. It provides a collaborative workspace for data scientists, engineers, and business users to process, analyze, and visualize big data. Databricks supports multiple programming languages, including Python, Scala, R, and SQL. It offers built-in integration with Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can also use Databricks to train and deploy machine learning models, and integrate with Azure Machine Learning.\"}, {\"category\": \"Analytics\"}], [{\"id\": \"83\"}, {\"title\": \"Azure Databricks\"}, {\"content\": \"Azure Databricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Databricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Databricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.\"}, {\"category\": \"Analytics\"}], [{\"id\": \"107\"}, {\"title\": \"Azure Data Bricks\"}, {\"content\": \"Azure Data Bricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Data Bricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Data Bricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.\"}, {\"category\": \"Analytics\"}]] </Context>\\n</Context>', source='tool_use_agent')]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by Evalutor Agent:[UserMessage(content='does databricks support r?', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"vectest\",\"search_query\":\"does databricks support r?\",\"top_k\":3} and tool result is: <Context>[[{\"id\": \"12\"}, {\"title\": \"Azure Databricks\"}, {\"content\": \"Azure Databricks is an Apache Spark-based analytics platform optimized for the Azure cloud. It provides a collaborative workspace for data scientists, engineers, and business users to process, analyze, and visualize big data. Databricks supports multiple programming languages, including Python, Scala, R, and SQL. It offers built-in integration with Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can also use Databricks to train and deploy machine learning models, and integrate with Azure Machine Learning.\"}, {\"category\": \"Analytics\"}], [{\"id\": \"83\"}, {\"title\": \"Azure Databricks\"}, {\"content\": \"Azure Databricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Databricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Databricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.\"}, {\"category\": \"Analytics\"}], [{\"id\": \"107\"}, {\"title\": \"Azure Data Bricks\"}, {\"content\": \"Azure Data Bricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Data Bricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Data Bricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.\"}, {\"category\": \"Analytics\"}]] </Context>\\n</Context>', source='tool_use_agent'), AssistantMessage(content='Response:Yes, Databricks supports R as one of the programming languages. It provides a collaborative workspace for data scientists, engineers, and business users to process, analyze, and visualize big data using R, among other languages like Python, Scala, and SQL [Source: Azure Databricks, Doc No.: 12].', source='qa_agent')]\n",
      "conversation_id delete: c1586809-d03d-437e-9212-9e9ae951a4a5\n",
      "\u001b[35m--------------------\u001b[0m\n",
      "Yes, Databricks supports R as one of the programming languages. It provides a collaborative workspace for data scientists, engineers, and business users to process, analyze, and visualize big data using R, along with other languages like Python, Scala, and SQL. It also offers built-in integration with Azure services [Source: Azure Databricks, Doc No.: 12].\n"
     ]
    }
   ],
   "source": [
    "response = await agnext_bot.start_multiagent_chat(\"does databricks support r?\", \"\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime.start() took 0.00 ms.\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by GroupChatManager:UserMessage(content='tell me about einstien.', source='User')\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by tool_use_agent:UserMessage(content='tell me about einstien.', source='User')\n",
      "[[{'id': '8dcb5aba-5000-4deb-800c-0b7e2d77354a'}, {'docName': 'azure-machine-learning-azureml-part4.pdf'}, {'pageNumber': '245'}, {'title': 'SK_math_planner Evaluation and Metrics Overview'}, {'content': \"... > chenlu-test-pf New evaluation × SK_math_planner-var Evaluation run display name * {batch run name}- OSS eval catch error [timestamp} flow.dag.yaml Runtime V Inputs myruntime V Schema Name Type Evaluation input mapping * text string Choose data asset for evaluation math_test_data (version 1) V v Outputs + Upload new data Name Valu result Simat math_planner D V Code O Preview of top 5 rows 1 import async 2 from promptf text groundtruth 3 import seman How many sheep wou ... 5 5 from semanti from plugins What would be the ar ... 6 17 import confi What would you have ... -1 11 @tool How many slices of pl ... 4 12 def my_pytho 13 # Initia What is the sum of 5 a ... 8 14 kernel - 15 # Add a 16 # kernel + 17 # kernel 18 kernel.a 19 20 planner 21 Submit Cancel Name Description Type Data source groundtruth string ${data.groundtruth} prediction string ${run.outputs.result) After running the evaluator, you'll get a summary back of your metrics. Initial runs may yield less than ideal results, which can be used as a motivation for immediate improvement. To check the metrics, you can go back to the batch run detail page, select the Details button, then select the Output tab, and select the evaluation run name in the dropdown list to view the evaluation result. Details - SK_math_planner-variant_0-202309141209 × Overview Outputs Logs Metrics Trace Snapshot C Refresh Export Append related results SK_math_planner-variant_0- v + Fold all cells SK_math_planner-variant_0- 202309141209-OSS eval cat Q Search ch error-202309141213 ₣ Filter Columns Line number text Status result groundtruth prediction score 0 How many sheep would Completed 5.0 5 1 you have if you started with 3 and got 2 more? 1 What would be the area Completed 6.0 6 6 1 of a rectangle with a sides of 2ft and 3ft? 2 What would you have Completed -1.0 -1 -1 1 left if you spent $3 when you only had $2 to begin 4 with 3 How many slices of pizza Completed 4.0 4 4 1 would everyone get if you split 12 slices You can check the aggregated metric in the Metrics tab. Details - SK_math_planner-variant_0-202309150728 Overview Outputs Logs Metrics Trace Snapshot C Refresh Export Name Status Created on Duration accuracy SK_math_planner-variant_0-202309150728-OSS eval catch error-20230915 Completed Sep 15, 2023 15:29 PM 12.50s 0.8 + \"}], [{'id': '6ab8950f-7958-411b-b3f9-569153665178'}, {'docName': 'autocad_aca_user_guide_english.pdf.part3.pdf'}, {'pageNumber': '149'}, {'title': 'Using the Model Explorer to Create Mass Models'}, {'content': 'For information about assigning materials to mass groups, see Assigning Materials to a Mass Group on page 1054. Using the Model Explorer to Create Mass Models The Model Explorer is a window in which you create, view, and manipulate mass elements and mass groups. You can create your entire conceptual model by using the Model Explorer. The main window is similar to the 3D orbit view. You can attach objects and mass elements to mass groups and view them in the Model Explorer. You can simultaneously view the conceptual and the hierarchical structure of mass groups and mass elements that make up the model. The Model Explorer is divided into three areas: the tree view in the left pane, the graphics area in the right pane, and the menu bar and toolbar across the top. Viewing a mass group in the Model Explorer Model Explorer - X File Edit View Help Conceptual v 8 SW Isometric v Project (Drawing1) Project (03 Furniture Plan) Project (02 Flaming) + (MassGroup) Handle: 27F4 Volume: 14 CF Left Pane of the Model Explorer The tree view lists all open drawings as Projects. Any mass groups are displayed under their associated drawing in the tree view. If you expand a mass group, the mass elements attached to it are displayed. One of the following icons is Using the Model Explorer to Create Mass Models | 1073 '}], [{'id': '14b3fd0f-c971-454f-a012-5d7cd059718c'}, {'docName': 'autocad_aca_user_guide_english.pdf.part3.pdf'}, {'pageNumber': '98'}, {'title': 'Combining Mass Elements Using Boolean Operations'}, {'content': 'If you want to ... Then ... save the changes to the current mass element right-click, and click Save Changes. The mass element uses the edited profile to define its geometry. Any other objects or styles that use this profile are also updated with the edited geometry. Combining Mass Elements Using Boolean Operations Use this procedure to combine mass elements using Boolean operations. 1 Select the mass element to which you want to join another mass element. 2 Selected the desired Boolean operation: If you want to ... Then ... combine the total volume of two or more mass elements into a com- posite object click Mass Element tab > Modify panel > Boolean drop- down > Union . remove the common area of one mass element from another click Mass Element tab > Modify panel > Boolean drop- down > Subtract . remove non-overlapping portions and create a composite solid from the common volume click Mass Element tab > Modify panel > Boolean drop-down > In- tersect . 3 Select the objects you want to combine, and press ENTER. 4 Enter y (Yes) to erase the original geometry, or enter n (No) to keep the original geometry in the drawing. NOTE A boolean operation creates a free form mass element. Due to the topological structure of the free form mass element, its facet deviation cannot be changed. The FACETDEV command will have no effect on an existing free form mass element. 1022 | Chapter 15 Creating Conceptual Models '}]]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by QA Agent:[UserMessage(content='tell me about einstien.', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"aml_index_with_suggester\",\"search_query\":\"about Einstein\"} and tool result is: <Context>[[{\"id\": \"8dcb5aba-5000-4deb-800c-0b7e2d77354a\"}, {\"docName\": \"azure-machine-learning-azureml-part4.pdf\"}, {\"pageNumber\": \"245\"}, {\"title\": \"SK_math_planner Evaluation and Metrics Overview\"}, {\"content\": \"... > chenlu-test-pf New evaluation \\\\u00d7 SK_math_planner-var Evaluation run display name * {batch run name}- OSS eval catch error [timestamp} flow.dag.yaml Runtime V Inputs myruntime V Schema Name Type Evaluation input mapping * text string Choose data asset for evaluation math_test_data (version 1) V v Outputs + Upload new data Name Valu result Simat math_planner D V Code O Preview of top 5 rows 1 import async 2 from promptf text groundtruth 3 import seman How many sheep wou ... 5 5 from semanti from plugins What would be the ar ... 6 17 import confi What would you have ... -1 11 @tool How many slices of pl ... 4 12 def my_pytho 13 # Initia What is the sum of 5 a ... 8 14 kernel - 15 # Add a 16 # kernel + 17 # kernel 18 kernel.a 19 20 planner 21 Submit Cancel Name Description Type Data source groundtruth string ${data.groundtruth} prediction string ${run.outputs.result) After running the evaluator, you\\'ll get a summary back of your metrics. Initial runs may yield less than ideal results, which can be used as a motivation for immediate improvement. To check the metrics, you can go back to the batch run detail page, select the Details button, then select the Output tab, and select the evaluation run name in the dropdown list to view the evaluation result. Details - SK_math_planner-variant_0-202309141209 \\\\u00d7 Overview Outputs Logs Metrics Trace Snapshot C Refresh Export Append related results SK_math_planner-variant_0- v + Fold all cells SK_math_planner-variant_0- 202309141209-OSS eval cat Q Search ch error-202309141213 \\\\u20a3 Filter Columns Line number text Status result groundtruth prediction score 0 How many sheep would Completed 5.0 5 1 you have if you started with 3 and got 2 more? 1 What would be the area Completed 6.0 6 6 1 of a rectangle with a sides of 2ft and 3ft? 2 What would you have Completed -1.0 -1 -1 1 left if you spent $3 when you only had $2 to begin 4 with 3 How many slices of pizza Completed 4.0 4 4 1 would everyone get if you split 12 slices You can check the aggregated metric in the Metrics tab. Details - SK_math_planner-variant_0-202309150728 Overview Outputs Logs Metrics Trace Snapshot C Refresh Export Name Status Created on Duration accuracy SK_math_planner-variant_0-202309150728-OSS eval catch error-20230915 Completed Sep 15, 2023 15:29 PM 12.50s 0.8 + \"}], [{\"id\": \"6ab8950f-7958-411b-b3f9-569153665178\"}, {\"docName\": \"autocad_aca_user_guide_english.pdf.part3.pdf\"}, {\"pageNumber\": \"149\"}, {\"title\": \"Using the Model Explorer to Create Mass Models\"}, {\"content\": \"For information about assigning materials to mass groups, see Assigning Materials to a Mass Group on page 1054. Using the Model Explorer to Create Mass Models The Model Explorer is a window in which you create, view, and manipulate mass elements and mass groups. You can create your entire conceptual model by using the Model Explorer. The main window is similar to the 3D orbit view. You can attach objects and mass elements to mass groups and view them in the Model Explorer. You can simultaneously view the conceptual and the hierarchical structure of mass groups and mass elements that make up the model. The Model Explorer is divided into three areas: the tree view in the left pane, the graphics area in the right pane, and the menu bar and toolbar across the top. Viewing a mass group in the Model Explorer Model Explorer - X File Edit View Help Conceptual v 8 SW Isometric v Project (Drawing1) Project (03 Furniture Plan) Project (02 Flaming) + (MassGroup) Handle: 27F4 Volume: 14 CF Left Pane of the Model Explorer The tree view lists all open drawings as Projects. Any mass groups are displayed under their associated drawing in the tree view. If you expand a mass group, the mass elements attached to it are displayed. One of the following icons is Using the Model Explorer to Create Mass Models | 1073 \"}], [{\"id\": \"14b3fd0f-c971-454f-a012-5d7cd059718c\"}, {\"docName\": \"autocad_aca_user_guide_english.pdf.part3.pdf\"}, {\"pageNumber\": \"98\"}, {\"title\": \"Combining Mass Elements Using Boolean Operations\"}, {\"content\": \"If you want to ... Then ... save the changes to the current mass element right-click, and click Save Changes. The mass element uses the edited profile to define its geometry. Any other objects or styles that use this profile are also updated with the edited geometry. Combining Mass Elements Using Boolean Operations Use this procedure to combine mass elements using Boolean operations. 1 Select the mass element to which you want to join another mass element. 2 Selected the desired Boolean operation: If you want to ... Then ... combine the total volume of two or more mass elements into a com- posite object click Mass Element tab > Modify panel > Boolean drop- down > Union . remove the common area of one mass element from another click Mass Element tab > Modify panel > Boolean drop- down > Subtract . remove non-overlapping portions and create a composite solid from the common volume click Mass Element tab > Modify panel > Boolean drop-down > In- tersect . 3 Select the objects you want to combine, and press ENTER. 4 Enter y (Yes) to erase the original geometry, or enter n (No) to keep the original geometry in the drawing. NOTE A boolean operation creates a free form mass element. Due to the topological structure of the free form mass element, its facet deviation cannot be changed. The FACETDEV command will have no effect on an existing free form mass element. 1022 | Chapter 15 Creating Conceptual Models \"}]] </Context>\\n</Context>', source='tool_use_agent')]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by Evalutor Agent:[UserMessage(content='tell me about einstien.', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"aml_index_with_suggester\",\"search_query\":\"about Einstein\"} and tool result is: <Context>[[{\"id\": \"8dcb5aba-5000-4deb-800c-0b7e2d77354a\"}, {\"docName\": \"azure-machine-learning-azureml-part4.pdf\"}, {\"pageNumber\": \"245\"}, {\"title\": \"SK_math_planner Evaluation and Metrics Overview\"}, {\"content\": \"... > chenlu-test-pf New evaluation \\\\u00d7 SK_math_planner-var Evaluation run display name * {batch run name}- OSS eval catch error [timestamp} flow.dag.yaml Runtime V Inputs myruntime V Schema Name Type Evaluation input mapping * text string Choose data asset for evaluation math_test_data (version 1) V v Outputs + Upload new data Name Valu result Simat math_planner D V Code O Preview of top 5 rows 1 import async 2 from promptf text groundtruth 3 import seman How many sheep wou ... 5 5 from semanti from plugins What would be the ar ... 6 17 import confi What would you have ... -1 11 @tool How many slices of pl ... 4 12 def my_pytho 13 # Initia What is the sum of 5 a ... 8 14 kernel - 15 # Add a 16 # kernel + 17 # kernel 18 kernel.a 19 20 planner 21 Submit Cancel Name Description Type Data source groundtruth string ${data.groundtruth} prediction string ${run.outputs.result) After running the evaluator, you\\'ll get a summary back of your metrics. Initial runs may yield less than ideal results, which can be used as a motivation for immediate improvement. To check the metrics, you can go back to the batch run detail page, select the Details button, then select the Output tab, and select the evaluation run name in the dropdown list to view the evaluation result. Details - SK_math_planner-variant_0-202309141209 \\\\u00d7 Overview Outputs Logs Metrics Trace Snapshot C Refresh Export Append related results SK_math_planner-variant_0- v + Fold all cells SK_math_planner-variant_0- 202309141209-OSS eval cat Q Search ch error-202309141213 \\\\u20a3 Filter Columns Line number text Status result groundtruth prediction score 0 How many sheep would Completed 5.0 5 1 you have if you started with 3 and got 2 more? 1 What would be the area Completed 6.0 6 6 1 of a rectangle with a sides of 2ft and 3ft? 2 What would you have Completed -1.0 -1 -1 1 left if you spent $3 when you only had $2 to begin 4 with 3 How many slices of pizza Completed 4.0 4 4 1 would everyone get if you split 12 slices You can check the aggregated metric in the Metrics tab. Details - SK_math_planner-variant_0-202309150728 Overview Outputs Logs Metrics Trace Snapshot C Refresh Export Name Status Created on Duration accuracy SK_math_planner-variant_0-202309150728-OSS eval catch error-20230915 Completed Sep 15, 2023 15:29 PM 12.50s 0.8 + \"}], [{\"id\": \"6ab8950f-7958-411b-b3f9-569153665178\"}, {\"docName\": \"autocad_aca_user_guide_english.pdf.part3.pdf\"}, {\"pageNumber\": \"149\"}, {\"title\": \"Using the Model Explorer to Create Mass Models\"}, {\"content\": \"For information about assigning materials to mass groups, see Assigning Materials to a Mass Group on page 1054. Using the Model Explorer to Create Mass Models The Model Explorer is a window in which you create, view, and manipulate mass elements and mass groups. You can create your entire conceptual model by using the Model Explorer. The main window is similar to the 3D orbit view. You can attach objects and mass elements to mass groups and view them in the Model Explorer. You can simultaneously view the conceptual and the hierarchical structure of mass groups and mass elements that make up the model. The Model Explorer is divided into three areas: the tree view in the left pane, the graphics area in the right pane, and the menu bar and toolbar across the top. Viewing a mass group in the Model Explorer Model Explorer - X File Edit View Help Conceptual v 8 SW Isometric v Project (Drawing1) Project (03 Furniture Plan) Project (02 Flaming) + (MassGroup) Handle: 27F4 Volume: 14 CF Left Pane of the Model Explorer The tree view lists all open drawings as Projects. Any mass groups are displayed under their associated drawing in the tree view. If you expand a mass group, the mass elements attached to it are displayed. One of the following icons is Using the Model Explorer to Create Mass Models | 1073 \"}], [{\"id\": \"14b3fd0f-c971-454f-a012-5d7cd059718c\"}, {\"docName\": \"autocad_aca_user_guide_english.pdf.part3.pdf\"}, {\"pageNumber\": \"98\"}, {\"title\": \"Combining Mass Elements Using Boolean Operations\"}, {\"content\": \"If you want to ... Then ... save the changes to the current mass element right-click, and click Save Changes. The mass element uses the edited profile to define its geometry. Any other objects or styles that use this profile are also updated with the edited geometry. Combining Mass Elements Using Boolean Operations Use this procedure to combine mass elements using Boolean operations. 1 Select the mass element to which you want to join another mass element. 2 Selected the desired Boolean operation: If you want to ... Then ... combine the total volume of two or more mass elements into a com- posite object click Mass Element tab > Modify panel > Boolean drop- down > Union . remove the common area of one mass element from another click Mass Element tab > Modify panel > Boolean drop- down > Subtract . remove non-overlapping portions and create a composite solid from the common volume click Mass Element tab > Modify panel > Boolean drop-down > In- tersect . 3 Select the objects you want to combine, and press ENTER. 4 Enter y (Yes) to erase the original geometry, or enter n (No) to keep the original geometry in the drawing. NOTE A boolean operation creates a free form mass element. Due to the topological structure of the free form mass element, its facet deviation cannot be changed. The FACETDEV command will have no effect on an existing free form mass element. 1022 | Chapter 15 Creating Conceptual Models \"}]] </Context>\\n</Context>', source='tool_use_agent'), AssistantMessage(content=\"Response:The provided context does not contain information about Einstein. Therefore, I cannot give a detailed response about Einstein. Please provide relevant context or documents, and I'd be happy to help.\", source='qa_agent')]\n",
      "conversation_id delete: 9f361bd8-11e9-43fc-98e3-e7a57f6f2507\n",
      "\u001b[35m--------------------\u001b[0m\n",
      "The answer cannot be provided.\n"
     ]
    }
   ],
   "source": [
    "response = await agnext_bot.start_multiagent_chat(\"tell me about einstien.\", \"\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogenv0.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
