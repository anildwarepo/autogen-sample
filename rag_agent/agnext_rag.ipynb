{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq = ['how to use gpu in machine learning?',\n",
    "        'is python support in azure functions?', \n",
    "        'does databricks support r?',\n",
    "        'tell me about einstien.',\n",
    "        'what are the limitations of Publishing Drawings to 3D DWF?',\n",
    "        'how to change the Railing Extensions at Floor Levels?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agnext_bot\n",
    "await agnext_bot.register_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime.start() took 0.00 ms.\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by GroupChatManager:UserMessage(content='how to use gpu in machine learning?', source='User')\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by tool_use_agent:UserMessage(content='how to use gpu in machine learning?', source='User')\n",
      "[[{'id': '6276f9e7-a795-4a33-a585-1fe4537bb7ec'}, {'docName': 'azure-machine-learning-azureml-part3.pdf'}, {'pageNumber': '288'}, {'title': 'Distributed GPU Training Guide (SDK v2)'}, {'content': \"Distributed GPU training guide (SDK v2) Article · 08/28/2024 APPLIES TO: Python SDK azure-ai-ml v2 (current) [2] Learn more about using distributed GPU training code in Azure Machine Learning. This article helps you run your existing distributed training code, and offers tips and examples for you to follow for each framework: · PyTorch · TensorFlow · Accelerate GPU training with InfiniBand Prerequisites Review the basic concepts of distributed GPU training, such as data parallelism, distributed data parallelism, and model parallelism. Q Tip If you don't know which type of parallelism to use, more than 90% of the time you should use distributed data parallelism. PyTorch Azure Machine Learning supports running distributed jobs using PyTorch's native distributed training capabilities (torch.distributed). Q Tip For data parallelism, the official PyTorch guidance4 is to use DistributedDataParallel (DDP) over DataParallel for both single-node and multi- node distributed training. PyTorch also recommends using DistributedDataParallel over the multiprocessing_package . Azure Machine Learning documentation and examples therefore focus on DistributedDataParallel training. Process group initialization \"}], [{'id': '9c368393-6bcc-491a-a245-3a600326646c'}, {'docName': 'azure-machine-learning-azureml-part6.pdf'}, {'pageNumber': '196'}, {'title': 'Setting Up GPU Cluster and Environment for Azure Machine Learning'}, {'content': \"compute: azureml : gpu-cluster environment : name: torch200-transformers-gpu image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8- ubuntu22.04: latest ® Important The environment torch200-transformers-gpu we've created requires a CUDA 11.8 compatible hardware device to run Torch 2.0 and Ubuntu 20.04. If your GPU device doesn't support this version of CUDA, you can check the alternative torch113-conda. yaml conda environment (also available on the repository), which runs Torch 1.3 over Ubuntu 18.04 with CUDA 10.1. However, acceleration using the optimum and accelerate libraries won't be supported on this configuration. 4. Each deployment runs on compute clusters. They support both Azure Machine Learning Compute clusters (AmlCompute) or Kubernetes clusters. In this example, our model can benefit from GPU acceleration, which is why we use a GPU cluster. Azure CLI Azure CLI az ml compute create -n gpu-cluster -- type amlcompute -- size STANDARD_NV6 -- min-instances 0 -- max-instances 2 1 Note You are not charged for compute at this point as the cluster remains at 0 nodes until a batch endpoint is invoked and a batch scoring job is submitted. Learn more about manage and optimize cost for AmlCompute. 5. Now, let's create the deployment. Azure CLI To create a new deployment under the created endpoint, create a YAML configuration like the following. You can check the full batch endpoint YAML \"}], [{'id': '1c06beca-9352-441a-a509-ffa7fc38d6b8'}, {'docName': 'azure-machine-learning-azureml-part3.pdf'}, {'pageNumber': '223'}, {'title': 'Setting Up and Running a GPU Cluster in Azure Machine Learning'}, {'content': \"You can also find a completed Jupyter Notebook version of this guide on the GitHub samples page. Before you can run the code in this article to create a GPU cluster, you'll need to request a quota increase for your workspace. Set up the job This section sets up the job for training by loading the required Python packages, connecting to a workspace, creating a compute resource to run a command job, and creating an environment to run the job. Connect to the workspace First, you need to connect to your Azure Machine Learning workspace. The Azure Machine Learning workspace is the top-level resource for the service. It provides you with a centralized place to work with all the artifacts you create when you use Azure Machine Learning. We're using DefaultAzureCredential to get access to the workspace. This credential should be capable of handling most Azure SDK authentication scenarios. If DefaultAzureCredential doesn't work for you, see azure-identity reference documentation or Set up authentication for more available credentials. Python # Handle to the workspace from azure. ai.ml import MLClient # Authentication package from azure. identity import DefaultAzureCredential credential = DefaultAzureCredential() If you prefer to use a browser to sign in and authenticate, you should uncomment the following code and use it instead. Python # Handle to the workspace # from azure.ai.ml import MLClient # Authentication package \"}]]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by QA Agent:[UserMessage(content='how to use gpu in machine learning?', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"aml_index_with_suggester\",\"search_query\":\"how to use gpu in machine learning\",\"top_k\":3} and tool result is: <Context>[[{\"id\": \"6276f9e7-a795-4a33-a585-1fe4537bb7ec\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"288\"}, {\"title\": \"Distributed GPU Training Guide (SDK v2)\"}, {\"content\": \"Distributed GPU training guide (SDK v2) Article \\\\u00b7 08/28/2024 APPLIES TO: Python SDK azure-ai-ml v2 (current) [2] Learn more about using distributed GPU training code in Azure Machine Learning. This article helps you run your existing distributed training code, and offers tips and examples for you to follow for each framework: \\\\u00b7 PyTorch \\\\u00b7 TensorFlow \\\\u00b7 Accelerate GPU training with InfiniBand Prerequisites Review the basic concepts of distributed GPU training, such as data parallelism, distributed data parallelism, and model parallelism. Q Tip If you don\\'t know which type of parallelism to use, more than 90% of the time you should use distributed data parallelism. PyTorch Azure Machine Learning supports running distributed jobs using PyTorch\\'s native distributed training capabilities (torch.distributed). Q Tip For data parallelism, the official PyTorch guidance4 is to use DistributedDataParallel (DDP) over DataParallel for both single-node and multi- node distributed training. PyTorch also recommends using DistributedDataParallel over the multiprocessing_package . Azure Machine Learning documentation and examples therefore focus on DistributedDataParallel training. Process group initialization \"}], [{\"id\": \"9c368393-6bcc-491a-a245-3a600326646c\"}, {\"docName\": \"azure-machine-learning-azureml-part6.pdf\"}, {\"pageNumber\": \"196\"}, {\"title\": \"Setting Up GPU Cluster and Environment for Azure Machine Learning\"}, {\"content\": \"compute: azureml : gpu-cluster environment : name: torch200-transformers-gpu image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8- ubuntu22.04: latest \\\\u00ae Important The environment torch200-transformers-gpu we\\'ve created requires a CUDA 11.8 compatible hardware device to run Torch 2.0 and Ubuntu 20.04. If your GPU device doesn\\'t support this version of CUDA, you can check the alternative torch113-conda. yaml conda environment (also available on the repository), which runs Torch 1.3 over Ubuntu 18.04 with CUDA 10.1. However, acceleration using the optimum and accelerate libraries won\\'t be supported on this configuration. 4. Each deployment runs on compute clusters. They support both Azure Machine Learning Compute clusters (AmlCompute) or Kubernetes clusters. In this example, our model can benefit from GPU acceleration, which is why we use a GPU cluster. Azure CLI Azure CLI az ml compute create -n gpu-cluster -- type amlcompute -- size STANDARD_NV6 -- min-instances 0 -- max-instances 2 1 Note You are not charged for compute at this point as the cluster remains at 0 nodes until a batch endpoint is invoked and a batch scoring job is submitted. Learn more about manage and optimize cost for AmlCompute. 5. Now, let\\'s create the deployment. Azure CLI To create a new deployment under the created endpoint, create a YAML configuration like the following. You can check the full batch endpoint YAML \"}], [{\"id\": \"1c06beca-9352-441a-a509-ffa7fc38d6b8\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"223\"}, {\"title\": \"Setting Up and Running a GPU Cluster in Azure Machine Learning\"}, {\"content\": \"You can also find a completed Jupyter Notebook version of this guide on the GitHub samples page. Before you can run the code in this article to create a GPU cluster, you\\'ll need to request a quota increase for your workspace. Set up the job This section sets up the job for training by loading the required Python packages, connecting to a workspace, creating a compute resource to run a command job, and creating an environment to run the job. Connect to the workspace First, you need to connect to your Azure Machine Learning workspace. The Azure Machine Learning workspace is the top-level resource for the service. It provides you with a centralized place to work with all the artifacts you create when you use Azure Machine Learning. We\\'re using DefaultAzureCredential to get access to the workspace. This credential should be capable of handling most Azure SDK authentication scenarios. If DefaultAzureCredential doesn\\'t work for you, see azure-identity reference documentation or Set up authentication for more available credentials. Python # Handle to the workspace from azure. ai.ml import MLClient # Authentication package from azure. identity import DefaultAzureCredential credential = DefaultAzureCredential() If you prefer to use a browser to sign in and authenticate, you should uncomment the following code and use it instead. Python # Handle to the workspace # from azure.ai.ml import MLClient # Authentication package \"}]] </Context>\\n</Context>', source='tool_use_agent')]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by Evalutor Agent:[UserMessage(content='how to use gpu in machine learning?', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"aml_index_with_suggester\",\"search_query\":\"how to use gpu in machine learning\",\"top_k\":3} and tool result is: <Context>[[{\"id\": \"6276f9e7-a795-4a33-a585-1fe4537bb7ec\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"288\"}, {\"title\": \"Distributed GPU Training Guide (SDK v2)\"}, {\"content\": \"Distributed GPU training guide (SDK v2) Article \\\\u00b7 08/28/2024 APPLIES TO: Python SDK azure-ai-ml v2 (current) [2] Learn more about using distributed GPU training code in Azure Machine Learning. This article helps you run your existing distributed training code, and offers tips and examples for you to follow for each framework: \\\\u00b7 PyTorch \\\\u00b7 TensorFlow \\\\u00b7 Accelerate GPU training with InfiniBand Prerequisites Review the basic concepts of distributed GPU training, such as data parallelism, distributed data parallelism, and model parallelism. Q Tip If you don\\'t know which type of parallelism to use, more than 90% of the time you should use distributed data parallelism. PyTorch Azure Machine Learning supports running distributed jobs using PyTorch\\'s native distributed training capabilities (torch.distributed). Q Tip For data parallelism, the official PyTorch guidance4 is to use DistributedDataParallel (DDP) over DataParallel for both single-node and multi- node distributed training. PyTorch also recommends using DistributedDataParallel over the multiprocessing_package . Azure Machine Learning documentation and examples therefore focus on DistributedDataParallel training. Process group initialization \"}], [{\"id\": \"9c368393-6bcc-491a-a245-3a600326646c\"}, {\"docName\": \"azure-machine-learning-azureml-part6.pdf\"}, {\"pageNumber\": \"196\"}, {\"title\": \"Setting Up GPU Cluster and Environment for Azure Machine Learning\"}, {\"content\": \"compute: azureml : gpu-cluster environment : name: torch200-transformers-gpu image: mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8- ubuntu22.04: latest \\\\u00ae Important The environment torch200-transformers-gpu we\\'ve created requires a CUDA 11.8 compatible hardware device to run Torch 2.0 and Ubuntu 20.04. If your GPU device doesn\\'t support this version of CUDA, you can check the alternative torch113-conda. yaml conda environment (also available on the repository), which runs Torch 1.3 over Ubuntu 18.04 with CUDA 10.1. However, acceleration using the optimum and accelerate libraries won\\'t be supported on this configuration. 4. Each deployment runs on compute clusters. They support both Azure Machine Learning Compute clusters (AmlCompute) or Kubernetes clusters. In this example, our model can benefit from GPU acceleration, which is why we use a GPU cluster. Azure CLI Azure CLI az ml compute create -n gpu-cluster -- type amlcompute -- size STANDARD_NV6 -- min-instances 0 -- max-instances 2 1 Note You are not charged for compute at this point as the cluster remains at 0 nodes until a batch endpoint is invoked and a batch scoring job is submitted. Learn more about manage and optimize cost for AmlCompute. 5. Now, let\\'s create the deployment. Azure CLI To create a new deployment under the created endpoint, create a YAML configuration like the following. You can check the full batch endpoint YAML \"}], [{\"id\": \"1c06beca-9352-441a-a509-ffa7fc38d6b8\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"223\"}, {\"title\": \"Setting Up and Running a GPU Cluster in Azure Machine Learning\"}, {\"content\": \"You can also find a completed Jupyter Notebook version of this guide on the GitHub samples page. Before you can run the code in this article to create a GPU cluster, you\\'ll need to request a quota increase for your workspace. Set up the job This section sets up the job for training by loading the required Python packages, connecting to a workspace, creating a compute resource to run a command job, and creating an environment to run the job. Connect to the workspace First, you need to connect to your Azure Machine Learning workspace. The Azure Machine Learning workspace is the top-level resource for the service. It provides you with a centralized place to work with all the artifacts you create when you use Azure Machine Learning. We\\'re using DefaultAzureCredential to get access to the workspace. This credential should be capable of handling most Azure SDK authentication scenarios. If DefaultAzureCredential doesn\\'t work for you, see azure-identity reference documentation or Set up authentication for more available credentials. Python # Handle to the workspace from azure. ai.ml import MLClient # Authentication package from azure. identity import DefaultAzureCredential credential = DefaultAzureCredential() If you prefer to use a browser to sign in and authenticate, you should uncomment the following code and use it instead. Python # Handle to the workspace # from azure.ai.ml import MLClient # Authentication package \"}]] </Context>\\n</Context>', source='tool_use_agent'), AssistantMessage(content='Response:To use GPUs in machine learning, particularly with Azure Machine Learning, follow these steps:\\n\\n1. **Distributed Training**:\\n   - Use frameworks like PyTorch or TensorFlow which support distributed GPU training to speed up the training process [Source: azure-machine-learning-azureml-part3.pdf, Page No.: 288].\\n   - Choose the appropriate type of parallelism for your task, with data parallelism being suitable for most use cases [Source: azure-machine-learning-azureml-part3.pdf, Page No.: 288].\\n\\n2. **Setting Up the Environment**:\\n   - Ensure your GPU hardware is compatible with the required CUDA version. For example, the environment `torch200-transformers-gpu` requires CUDA 11.8 [Source: azure-machine-learning-azureml-part6.pdf, Page No.: 196].\\n   - Set up a suitable compute cluster that supports GPU. You can create a GPU cluster using Azure CLI with commands such as:\\n     ```shell\\n     az ml compute create -n gpu-cluster --type amlcompute --size STANDARD_NV6 --min-instances 0 --max-instances 2\\n     ```\\n     This configuration allows the GPU cluster to scale from 0 to 2 instances depending on the requirement [Source: azure-machine-learning-azureml-part6.pdf, Page No.: 196].\\n\\n3. **Running the Job**:\\n   - Connect to your Azure Machine Learning workspace:\\n     ```python\\n     from azure.ai.ml import MLClient\\n     from azure.identity import DefaultAzureCredential\\n\\n     credential = DefaultAzureCredential()\\n     ml_client = MLClient(DefaultAzureCredential(), \"<subscription_id>\", \"<resource_group_name>\", \"<workspace_name>\")\\n     ```\\n   - Set up and configure the job for inferencing or training, making sure to specify the correct environment and compute resources [Source: azure-machine-learning-azureml-part3.pdf, Page No.: 223].\\n\\nBy following these steps, you can leverage GPU capabilities to enhance your machine learning tasks, particularly for compute-intensive deep learning models.', source='qa_agent')]\n",
      "conversation_id delete: 3889b2dd-a376-41e6-9dca-a951715edd37\n",
      "\u001b[35m--------------------\u001b[0m\n",
      "```markdown\n",
      "To use GPUs in machine learning, particularly with Azure Machine Learning, follow these steps:\n",
      "\n",
      "1. **Distributed Training**:\n",
      "   - Use frameworks like PyTorch or TensorFlow which support distributed GPU training to speed up the training process [Source: azure-machine-learning-azureml-part3.pdf, Page No.: 288].\n",
      "   - Choose the appropriate type of parallelism for your task, with data parallelism being suitable for most use cases [Source: azure-machine-learning-azureml-part3.pdf, Page No.: 288].\n",
      "\n",
      "2. **Setting Up the Environment**:\n",
      "   - Ensure your GPU hardware is compatible with the required CUDA version. For example, the environment `torch200-transformers-gpu` requires CUDA 11.8 [Source: azure-machine-learning-azureml-part6.pdf, Page No.: 196].\n",
      "   - Set up a suitable compute cluster that supports GPU. You can create a GPU cluster using Azure CLI with commands such as:\n",
      "     ```shell\n",
      "     az ml compute create -n gpu-cluster --type amlcompute --size STANDARD_NV6 --min-instances 0 --max-instances 2\n",
      "     ```\n",
      "     This configuration allows the GPU cluster to scale from 0 to 2 instances depending on the requirement [Source: azure-machine-learning-azureml-part6.pdf, Page No.: 196].\n",
      "\n",
      "3. **Running the Job**:\n",
      "   - Connect to your Azure Machine Learning workspace:\n",
      "     ```python\n",
      "     from azure.ai.ml import MLClient\n",
      "     from azure.identity import DefaultAzureCredential\n",
      "\n",
      "     credential = DefaultAzureCredential()\n",
      "     ml_client = MLClient(DefaultAzureCredential(), \"<subscription_id>\", \"<resource_group_name>\", \"<workspace_name>\")\n",
      "     ```\n",
      "   - Set up and configure the job for inferencing or training, making sure to specify the correct environment and compute resources [Source: azure-machine-learning-azureml-part3.pdf, Page No.: 223].\n",
      "\n",
      "By following these steps, you can leverage GPU capabilities to enhance your machine learning tasks, particularly for compute-intensive deep learning models.\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = await agnext_bot.start_multiagent_chat(\"how to use gpu in machine learning?\", \"\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime.start() took 0.00 ms.\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by GroupChatManager:UserMessage(content='does databricks support r?', source='User')\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by tool_use_agent:UserMessage(content='does databricks support r?', source='User')\n",
      "[[{'id': '12'}, {'title': 'Azure Databricks'}, {'content': 'Azure Databricks is an Apache Spark-based analytics platform optimized for the Azure cloud. It provides a collaborative workspace for data scientists, engineers, and business users to process, analyze, and visualize big data. Databricks supports multiple programming languages, including Python, Scala, R, and SQL. It offers built-in integration with Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can also use Databricks to train and deploy machine learning models, and integrate with Azure Machine Learning.'}, {'category': 'Analytics'}], [{'id': '83'}, {'title': 'Azure Databricks'}, {'content': 'Azure Databricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Databricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Databricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.'}, {'category': 'Analytics'}], [{'id': '107'}, {'title': 'Azure Data Bricks'}, {'content': 'Azure Data Bricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Data Bricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Data Bricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.'}, {'category': 'Analytics'}]]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by QA Agent:[UserMessage(content='does databricks support r?', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"vectest\",\"search_query\":\"does databricks support R\"} and tool result is: <Context>[[{\"id\": \"12\"}, {\"title\": \"Azure Databricks\"}, {\"content\": \"Azure Databricks is an Apache Spark-based analytics platform optimized for the Azure cloud. It provides a collaborative workspace for data scientists, engineers, and business users to process, analyze, and visualize big data. Databricks supports multiple programming languages, including Python, Scala, R, and SQL. It offers built-in integration with Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can also use Databricks to train and deploy machine learning models, and integrate with Azure Machine Learning.\"}, {\"category\": \"Analytics\"}], [{\"id\": \"83\"}, {\"title\": \"Azure Databricks\"}, {\"content\": \"Azure Databricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Databricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Databricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.\"}, {\"category\": \"Analytics\"}], [{\"id\": \"107\"}, {\"title\": \"Azure Data Bricks\"}, {\"content\": \"Azure Data Bricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Data Bricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Data Bricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.\"}, {\"category\": \"Analytics\"}]] </Context>\\n</Context>', source='tool_use_agent')]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by Evalutor Agent:[UserMessage(content='does databricks support r?', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"vectest\",\"search_query\":\"does databricks support R\"} and tool result is: <Context>[[{\"id\": \"12\"}, {\"title\": \"Azure Databricks\"}, {\"content\": \"Azure Databricks is an Apache Spark-based analytics platform optimized for the Azure cloud. It provides a collaborative workspace for data scientists, engineers, and business users to process, analyze, and visualize big data. Databricks supports multiple programming languages, including Python, Scala, R, and SQL. It offers built-in integration with Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can also use Databricks to train and deploy machine learning models, and integrate with Azure Machine Learning.\"}, {\"category\": \"Analytics\"}], [{\"id\": \"83\"}, {\"title\": \"Azure Databricks\"}, {\"content\": \"Azure Databricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Databricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Databricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.\"}, {\"category\": \"Analytics\"}], [{\"id\": \"107\"}, {\"title\": \"Azure Data Bricks\"}, {\"content\": \"Azure Data Bricks is a fully managed, Apache Spark-based analytics platform that enables you to process and analyze large volumes of data. It provides features like collaborative notebooks, job scheduling, and integration with Azure Machine Learning. Data Bricks supports various data sources, such as Azure Blob Storage, Azure Data Lake Storage, and Azure Cosmos DB. You can use Azure Data Bricks to build data lakes, develop big data analytics solutions, and train machine learning models. It also integrates with other Azure services, such as Azure Synapse Analytics and Azure Data Factory.\"}, {\"category\": \"Analytics\"}]] </Context>\\n</Context>', source='tool_use_agent'), AssistantMessage(content='Response:Yes, Databricks supports the R programming language alongside other languages such as Python, Scala, and SQL [Source: Azure Databricks].', source='qa_agent')]\n",
      "conversation_id delete: 96cdc4d2-2e92-4309-8683-1090abaabf18\n",
      "\u001b[35m--------------------\u001b[0m\n",
      "Yes, Databricks supports the R programming language alongside other languages such as Python, Scala, and SQL.\n",
      "\n",
      "Context sources:\n",
      "1. \"Databricks supports multiple programming languages, including Python, Scala, R, and SQL.\"\n"
     ]
    }
   ],
   "source": [
    "response = await agnext_bot.start_multiagent_chat(\"does databricks support r?\", \"\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime.start() took 0.00 ms.\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by GroupChatManager:UserMessage(content='tell me about einstien.', source='User')\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by tool_use_agent:UserMessage(content='tell me about einstien.', source='User')\n",
      "[[{'id': '343c7d25-2830-4351-b8a2-355a0eaa901f'}, {'docName': 'azure-machine-learning-azureml-part3.pdf'}, {'pageNumber': '490'}, {'title': 'Details about Washington D.C.'}, {'content': '\"top_n\": 3 } Response example JSON { \"id\": \"571e6744-3074-457f-8935-08646a3352fb\", \"results\": [ { \"document\": { \"Content\": \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. The President of the USA and many major national government offices are in the territory. This makes it the political center of the United States of America.\", \"Title\": \"Details about Washington D. C\" \"index\": 0, \"relevance_score\": 0.98347044 { \"document\": { \"Content\": \"Carson City is the capital city of the American state of Nevada. \", \"Title\": \"Facts about Carson City\" }, \"index\": 1, \"relevance_score\": 0.07172112 }, { \"document\": { \"Content\": \"Micronesia, officially the Federated States of Micronesia, is an island nation in the Pacific Ocean, northeast of Papua New Guinea. The country is a sovereign state in free association with the United States. The capital city of Federated States of Micronesia is Palikir.\", \"Title\": \"Micronesia\" }, \"index\": 3, \"relevance_score\": 0.05281402 }, { \"document\": { \"Content\": \"North Dakota is a state in the United States. 672, 591 people lived in North Dakota in the year 2010. The capital and seat of government is Bismarck.\", \"Title\": \"North Dakota\" }, \"index\": 2, \"relevance_score\": 0.03138043 '}]]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by QA Agent:[UserMessage(content='tell me about einstien.', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"aml_index_with_suggester\",\"search_query\":\"tell me about Einstein\",\"top_k\":1} and tool result is: <Context>[[{\"id\": \"343c7d25-2830-4351-b8a2-355a0eaa901f\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"490\"}, {\"title\": \"Details about Washington D.C.\"}, {\"content\": \"\\\\\"top_n\\\\\": 3 } Response example JSON { \\\\\"id\\\\\": \\\\\"571e6744-3074-457f-8935-08646a3352fb\\\\\", \\\\\"results\\\\\": [ { \\\\\"document\\\\\": { \\\\\"Content\\\\\": \\\\\"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. The President of the USA and many major national government offices are in the territory. This makes it the political center of the United States of America.\\\\\", \\\\\"Title\\\\\": \\\\\"Details about Washington D. C\\\\\" \\\\\"index\\\\\": 0, \\\\\"relevance_score\\\\\": 0.98347044 { \\\\\"document\\\\\": { \\\\\"Content\\\\\": \\\\\"Carson City is the capital city of the American state of Nevada. \\\\\", \\\\\"Title\\\\\": \\\\\"Facts about Carson City\\\\\" }, \\\\\"index\\\\\": 1, \\\\\"relevance_score\\\\\": 0.07172112 }, { \\\\\"document\\\\\": { \\\\\"Content\\\\\": \\\\\"Micronesia, officially the Federated States of Micronesia, is an island nation in the Pacific Ocean, northeast of Papua New Guinea. The country is a sovereign state in free association with the United States. The capital city of Federated States of Micronesia is Palikir.\\\\\", \\\\\"Title\\\\\": \\\\\"Micronesia\\\\\" }, \\\\\"index\\\\\": 3, \\\\\"relevance_score\\\\\": 0.05281402 }, { \\\\\"document\\\\\": { \\\\\"Content\\\\\": \\\\\"North Dakota is a state in the United States. 672, 591 people lived in North Dakota in the year 2010. The capital and seat of government is Bismarck.\\\\\", \\\\\"Title\\\\\": \\\\\"North Dakota\\\\\" }, \\\\\"index\\\\\": 2, \\\\\"relevance_score\\\\\": 0.03138043 \"}]] </Context>\\n</Context>', source='tool_use_agent')]\n",
      "\u001b[32m--------------------\u001b[0m\n",
      "Received by Evalutor Agent:[UserMessage(content='tell me about einstien.', source='User'), UserMessage(content='<Context>\\n Tool name is: retrieve_search_results, tool input is: {\"index_name\":\"aml_index_with_suggester\",\"search_query\":\"tell me about Einstein\",\"top_k\":1} and tool result is: <Context>[[{\"id\": \"343c7d25-2830-4351-b8a2-355a0eaa901f\"}, {\"docName\": \"azure-machine-learning-azureml-part3.pdf\"}, {\"pageNumber\": \"490\"}, {\"title\": \"Details about Washington D.C.\"}, {\"content\": \"\\\\\"top_n\\\\\": 3 } Response example JSON { \\\\\"id\\\\\": \\\\\"571e6744-3074-457f-8935-08646a3352fb\\\\\", \\\\\"results\\\\\": [ { \\\\\"document\\\\\": { \\\\\"Content\\\\\": \\\\\"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. The President of the USA and many major national government offices are in the territory. This makes it the political center of the United States of America.\\\\\", \\\\\"Title\\\\\": \\\\\"Details about Washington D. C\\\\\" \\\\\"index\\\\\": 0, \\\\\"relevance_score\\\\\": 0.98347044 { \\\\\"document\\\\\": { \\\\\"Content\\\\\": \\\\\"Carson City is the capital city of the American state of Nevada. \\\\\", \\\\\"Title\\\\\": \\\\\"Facts about Carson City\\\\\" }, \\\\\"index\\\\\": 1, \\\\\"relevance_score\\\\\": 0.07172112 }, { \\\\\"document\\\\\": { \\\\\"Content\\\\\": \\\\\"Micronesia, officially the Federated States of Micronesia, is an island nation in the Pacific Ocean, northeast of Papua New Guinea. The country is a sovereign state in free association with the United States. The capital city of Federated States of Micronesia is Palikir.\\\\\", \\\\\"Title\\\\\": \\\\\"Micronesia\\\\\" }, \\\\\"index\\\\\": 3, \\\\\"relevance_score\\\\\": 0.05281402 }, { \\\\\"document\\\\\": { \\\\\"Content\\\\\": \\\\\"North Dakota is a state in the United States. 672, 591 people lived in North Dakota in the year 2010. The capital and seat of government is Bismarck.\\\\\", \\\\\"Title\\\\\": \\\\\"North Dakota\\\\\" }, \\\\\"index\\\\\": 2, \\\\\"relevance_score\\\\\": 0.03138043 \"}]] </Context>\\n</Context>', source='tool_use_agent'), AssistantMessage(content='Response:The current context does not provide any information about Einstein. For specific details on Albert Einstein, additional information sources would be required.', source='qa_agent')]\n",
      "conversation_id delete: 53db2f7c-0740-4af0-9a49-1d6d6ea21e2e\n",
      "\u001b[35m--------------------\u001b[0m\n",
      "The answer cannot be provided.\n"
     ]
    }
   ],
   "source": [
    "response = await agnext_bot.start_multiagent_chat(\"tell me about einstien.\", \"\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogenv0.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
